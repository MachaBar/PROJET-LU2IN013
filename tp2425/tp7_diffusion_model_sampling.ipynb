{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MachaBar/PROJET-LU2IN013/blob/main/tp2425/tp7_diffusion_model_sampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3wSq73fLtQa"
      },
      "source": [
        "# Diffusion models: Sampling and conditional sampling of a pretrained DDPM model\n",
        "\n",
        "This notebook is based on the [github repository](https://github.com/DPS2022/diffusion-posterior-sampling.git) of\n",
        "\n",
        "*Diffusion Posterior Sampling for General Noisy Inverse Problems*, <br/>\n",
        "by Hyungjin Chung, Jeongsol Kim, Michael T. Mccann, Marc L. Klasky, Jong Chul Ye, <br/>\n",
        "ICLR 2023, https://arxiv.org/abs/2209.14687\n",
        "\n",
        "We use the U-net trained by the authors on the FFHQ datasets (using 49k images, ```01000.png``` to ```49999.png```).\n",
        "\n",
        "It is a DDPM model based on\n",
        "\n",
        "* Diffusion Models Beat GANs on Image Synthesis, Prafulla Dhariwal, Alex Nichol, NeurIPS 2021, https://arxiv.org/abs/2105.05233\n",
        "[github](https://github.com/openai/guided-diffusion/)\n",
        "\n",
        "* Denoising Diffusion Probabilistic Models, Jonathan Ho, Ajay Jain, Pieter Abbeel, NeurIPS 2020, https://arxiv.org/abs/2006.11239\n",
        "[projectpage](https://hojonathanho.github.io/diffusion/)\n",
        "\n",
        "**Notebook author:**\n",
        "* Bruno Galerne: www.idpoisson.fr/galerne / https://github.com/bgalerne\n",
        "\n",
        "\n",
        "$\\newcommand{\\bx}{\\mathbf{x}} % bold x$\n",
        "$\\newcommand{\\bz}{\\mathbf{z}} % bold z$\n",
        "$\\newcommand{\\bw}{\\mathbf{w}} % bold w$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suFs9kiEMIYa"
      },
      "source": [
        "# Download files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HlRnEGgMHSO"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/DPS2022/diffusion-posterior-sampling.git\n",
        "!cp -r diffusion-posterior-sampling/guided_diffusion guided_diffusion\n",
        "!wget -nc -O ffhq256-1k-validation.zip 'https://www.dropbox.com/scl/fi/pppstbdsf0em6o0qscruc/ffhq256-1k-validation.zip?rlkey=xl7nwv2nxb6yvsirr3wad77hm'\n",
        "!unzip -nq ffhq256-1k-validation.zip\n",
        "!wget -nc -O ffhq_10m.pt 'https://www.dropbox.com/scl/fi/pq72vxzxcbygieq5z4gvf/ffhq_10m.pt?rlkey=5sxdj6r4o9f7b7bbp5fxg2f5r'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4s3JciciLmvE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from guided_diffusion.unet import create_model\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NF1v4oU7PQTN"
      },
      "source": [
        "# Display functions\n",
        "We will work with PyTorch images with color values in $[-1,1]$ and the usual additional batch dimension.\n",
        "Images will have size 1x3x256x256 in PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxHHc0A4Lskr"
      },
      "outputs": [],
      "source": [
        "def pilimg_to_tensor(pil_img):\n",
        "  t = torchvision.transforms.ToTensor()(pil_img)\n",
        "  t = 2*t-1 # [0,1]->[-1,1]\n",
        "  t = t.unsqueeze(0)\n",
        "  t = t.to(device)\n",
        "  return(t)\n",
        "\n",
        "def display_as_pilimg(t):\n",
        "  t = 0.5+0.5*t.to('cpu')\n",
        "  t = t.squeeze()\n",
        "  t = t.clamp(0.,1.)\n",
        "  pil_img = torchvision.transforms.ToPILImage()(t)\n",
        "  display(pil_img)\n",
        "  return(pil_img)\n",
        "\n",
        "idx = np.random.randint(1000)\n",
        "print('Image', str(idx).zfill(5))\n",
        "img_pil = Image.open('ffhq256-1k-validation/'+str(idx).zfill(5)+'.png')\n",
        "display(img_pil)\n",
        "display_as_pilimg(pilimg_to_tensor(img_pil));\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDDJMYOQbMV6"
      },
      "source": [
        "# Load DDPM Unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sd1A0WSxP_JB"
      },
      "outputs": [],
      "source": [
        "# Load model\n",
        "model_config = {'image_size': 256,\n",
        "                'num_channels': 128,\n",
        "                'num_res_blocks': 1,\n",
        "                'channel_mult': '',\n",
        "                'learn_sigma': True,\n",
        "                'class_cond': False,\n",
        "                'use_checkpoint': False,\n",
        "                'attention_resolutions': 16,\n",
        "                'num_heads': 4,\n",
        "                'num_head_channels': 64,\n",
        "                'num_heads_upsample': -1,\n",
        "                'use_scale_shift_norm': True,\n",
        "                'dropout': 0.0,\n",
        "                'resblock_updown': True,\n",
        "                'use_fp16': False,\n",
        "                'use_new_attention_order': False,\n",
        "                'model_path': 'ffhq_10m.pt'}\n",
        "model = create_model(**model_config)\n",
        "model = model.to(device)\n",
        "# use in eval mode:\n",
        "model.eval();\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90ZFfhQObVd0"
      },
      "source": [
        "# DDPM class\n",
        "\n",
        "The DDPM class defined below will be used to sample the DDPM model.\n",
        "\n",
        "The Unet ```model``` estimates the residual noise $\\varepsilon_t(\\bx_t, t)$ from a noisy image $(\\bx_t, t)$.\n",
        "\n",
        "The method ```get_eps_from_model(self, x, t)``` computes $\\varepsilon_t(\\bx_t, t)$.\n",
        "\n",
        "The method ```predict_xstart_from_eps(self, x, eps, t)``` computes\n",
        "\n",
        "$$\n",
        "\\hat{\\bx_0}(\\bx_t) = \\frac{1}{\\sqrt{\\bar{\\alpha}_t}} \\bx_t\n",
        "- \\sqrt{\\frac{1}{\\bar{\\alpha}_t}-1} \\;  \\varepsilon_t(\\bx_t, t).\n",
        "$$\n",
        "\n",
        "In the following exercises, you will have to complete methods `sample` and `posterior_sampling` defined in this class.\n",
        "\n",
        "Remark that several variables are already precomputed in the class:\n",
        "* `self.num_diffusion_timesteps` : $T$\n",
        "* `self.reversed_time_steps` : backward $t$ range:  $\\{T, T-1, \\ldots, 1\\}$\n",
        "* `self.betas` : $(\\beta_t)_{1 \\leq t \\leq T}$\n",
        "* `self.alphas` : $(\\alpha_t)_{1 \\leq t \\leq T}$\n",
        "* `self.alphas_cumprod` : $(\\bar{\\alpha}_t)_{1 \\leq t \\leq T}$\n",
        "* `self.alphas_cumprod_prev` : $(\\bar{\\alpha}_{t-1})_{1 \\leq t \\leq T}$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBq6LVrRSh2S"
      },
      "outputs": [],
      "source": [
        "class DDPM:\n",
        "  def __init__(self, model=model):\n",
        "    self.num_diffusion_timesteps = 1000\n",
        "    self.reversed_time_steps = np.arange(self.num_diffusion_timesteps)[::-1]\n",
        "    beta_start = 0.0001\n",
        "    beta_end = 0.02\n",
        "    self.betas = np.linspace(beta_start, beta_end, self.num_diffusion_timesteps,\n",
        "                              dtype=np.float64)\n",
        "    self.alphas = 1.0 - self.betas\n",
        "    self.alphas_cumprod = np.cumprod(self.alphas, axis=0)\n",
        "    self.alphas_cumprod_prev = np.append(1.0, self.alphas_cumprod[:-1])\n",
        "    self.model = model\n",
        "    self.imgshape = (1,3,256,256)\n",
        "\n",
        "\n",
        "  def get_eps_from_model(self, x, t):\n",
        "    # the model outputs:\n",
        "    # - an estimation of the noise eps (chanels 0 to 2)\n",
        "    # - learnt variances for the posterior  (chanels 3 to 5)\n",
        "    # (see Improved Denoising Diffusion Probabilistic Models\n",
        "    # by Alex Nichol, Prafulla Dhariwal\n",
        "    # for the parameterization)\n",
        "    # We discard the second part of the output for this practice session.\n",
        "    model_output = self.model(x, torch.tensor(t, device=device).unsqueeze(0))\n",
        "    model_output = model_output[:,:3,:,:]\n",
        "    return(model_output)\n",
        "\n",
        "  def predict_xstart_from_eps(self, x, eps, t):\n",
        "    x_start = (\n",
        "        np.sqrt(1.0 / self.alphas_cumprod[t])* x\n",
        "        - np.sqrt(1.0 / self.alphas_cumprod[t] - 1) * eps\n",
        "    )\n",
        "    x_start = x_start.clamp(-1.,1.)\n",
        "    return(x_start)\n",
        "\n",
        "  def sample(self, show_steps=True):\n",
        "    with torch.no_grad():  # avoid backprop wrt model parameters\n",
        "      x = torch.randn(self.imgshape,device=device)  # initialize x_t for t=T\n",
        "      for i, t in enumerate(self.reversed_time_steps):\n",
        "\n",
        "          #TODO\n",
        "\n",
        "          if i==0 or t%100==0 or t==0:\n",
        "            print('Iteration:', i, '; Discrete time:', t)\n",
        "\n",
        "    return(x)\n",
        "\n",
        "  def posterior_sampling(self, linear_operator, y, x_true=None, show_steps=True, vis_y=None):\n",
        "\n",
        "    # visualization image for the observation y:\n",
        "    if vis_y==None:\n",
        "      vis_y = y\n",
        "\n",
        "    # initialize xt for t=T\n",
        "    x = torch.randn(self.imgshape,device=device)\n",
        "    x.requires_grad = True\n",
        "\n",
        "    # TODO\n",
        "\n",
        "    return(x)\n",
        "\n",
        "\n",
        "ddpm = DDPM()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMG7jPtR6S-6"
      },
      "source": [
        "<br/><br/><br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUNKWONCWCnS"
      },
      "source": [
        "# Exercise 1: Denoiser visualization\n",
        "1. Take an image from FFHQ validation set and apply the forward model to it:\n",
        "$$\n",
        "\\bx_{t+1} = \\sqrt{\\alpha_t} \\bx_t + \\sqrt{\\beta_t} \\bz_t\n",
        "$$\n",
        "Display $\\bx_t$ and $\\hat{\\bx_0}(\\bx_t)$ for 10 different levels.\n",
        "\n",
        "2. Display the two curves of the PSNR$(\\bx_t,\\bx_0)$ and PSNR$(\\hat{\\bx_0}(\\bx_t),\\bx_0)$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiWV24nOXR1m"
      },
      "outputs": [],
      "source": [
        "#Exercise 1:\n",
        "# Image 00462\n",
        "idx = 462\n",
        "img_pil = Image.open('ffhq256-1k-validation/'+str(idx).zfill(5)+'.png')\n",
        "x0 = pilimg_to_tensor(img_pil)\n",
        "psnr_noisy = []\n",
        "psnr_denoised = []\n",
        "\n",
        "def mypsnr(x,y):\n",
        "  error = torch.mean((x-y)**2).item()\n",
        "  psnr = 10*np.log10(2**2/error)\n",
        "  return(psnr)\n",
        "\n",
        "xt = x0.clone() # initialize xt for t=0\n",
        "for t in range(ddpm.num_diffusion_timesteps):\n",
        "\n",
        "  with torch.no_grad(): # avoid backprop wrt model parameters\n",
        "\n",
        "    # TODO\n",
        "\n",
        "    if (t+1)%100==0:\n",
        "      print('Iteration :', t+1)\n",
        "      pilimg = display_as_pilimg(torch.cat((xt, xhat, x0), dim=3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ck6Lja1_-lec"
      },
      "outputs": [],
      "source": [
        "# TODO Q2 plot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLBjoX1T6S-6"
      },
      "source": [
        "<br/><br/><br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTsw-SyUi5h7"
      },
      "source": [
        "# Exercise 2: Sampling\n",
        "1. Complete the method `sample` of the DDPM class.\n",
        "Let us recall that the DDPM transition probability is given by\n",
        "$$ p_\\theta(\\bx_{t-1}|\\bx_{t}) = \\mathcal{N}(\\mu_\\theta(\\bx_{t}, t), \\beta_t I_d) $$\n",
        "where\n",
        "$$\n",
        "\\mu_\\theta(\\bx_t, t) = \\frac{1}{\\sqrt{\\alpha_t}} \\left(\\bx_t - \\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}_t}}\\mathbf{\\varepsilon}_\\theta(\\bx_t,t) \\right).\n",
        "$$\n",
        "\n",
        "2. Add an option to the method ```sample``` to display both $\\bx_t$ and $\\hat{\\bx_0}(\\bx_t,t)$ every 100 iterations. Observe the evolution of the samples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaHxo0W_i4Ii"
      },
      "outputs": [],
      "source": [
        "sample = ddpm.sample()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsl1yrkG6S-7"
      },
      "source": [
        "<br/><br/><br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et6ZYFPVHSJy"
      },
      "source": [
        "# Exercise 3: Conditional sampling for imaging inverse problems\n",
        "\n",
        "We will perform conditional sampling for linear inverse problems based on\n",
        "\n",
        "*Diffusion Posterior Sampling for General Noisy Inverse Problems*,<br/>\n",
        "by Hyungjin Chung, Jeongsol Kim, Michael T. Mccann, Marc L. Klasky, Jong Chul Ye,<br/>\n",
        "ICLR 2023, https://arxiv.org/abs/2209.14687\n",
        "\n",
        "We restrict to linear measurements with Gaussian noise (eg inpainting, super-resolution, deblurring,...).\n",
        "\n",
        "The algorithm is the following:\n",
        "given\n",
        "$\\mathbf{y} = A \\bx + \\eta$ where $A$ is a linear operator and $\\eta$ is some Gaussian additive noise, we want to approximately sample\n",
        "$$\n",
        "p_\\theta(\\bx_0| \\mathbf{y} = A \\bx_0 + \\eta).\n",
        "$$\n",
        "This is performed by adding a correction term to the sampling procedure:\n",
        "\n",
        "\n",
        "> Initialize $x_T$ as for unconditional sampling.\n",
        ">\n",
        "> For $t=T$ to $1$:\n",
        ">  1. Predict $\\hat{\\bx_0}(\\bx_t,t)$.\n",
        ">  2. Compute the squared $\\ell^2$ error $\\|A\\hat{\\bx_0}(\\bx_t,t) - \\mathbf{y} \\|^2$.\n",
        ">  3. Define\n",
        ">  $$ \\bx_{t-1} = \\mu_\\theta(\\bx_{t}, t) + \\sqrt{\\beta_t} \\bz - \\zeta_t \\nabla_{\\bx_t} \\|A\\hat{\\bx_0}(\\bx_t,t) - \\mathbf{y} \\|^2. $$\n",
        "> where the scaling factor $\\zeta_t$ has been experimentally fixed as\n",
        "$$\n",
        "\\zeta_t =\n",
        "0.1\\times \\|A\\hat{\\bx_0}(\\bx_t,t) - \\mathbf{y}\\|^{-1}.\n",
        "$$\n",
        "\n",
        "Note that computing $\\nabla_{\\bx_t} \\|A\\hat{\\bx_0}(\\bx_t,t) - \\mathbf{y} \\|^2$ involves a backpropagation through the Unet so one can expect the conditional sampling to be twice as long as the sampling procedure.\n",
        "\n",
        "**Questions:**\n",
        "\n",
        "1. Add a method ```posterior_sampling```to the DDPM class with prototype <br/>\n",
        "`posterior_sampling(self, linear_operator, y, x_true=None, show_steps=True, viz_y = None)` <br/>\n",
        "that allows to display every 100 iterations the images $\\bx_t$, $\\hat{\\bx_0}(\\bx_t,t)$ as well as the observation $\\mathbf{y}$, and the groundtruth image $\\bx_0$ if given. <br/>\n",
        "(We suppose that there is a natural way defined by tensor ```vis_y``` to visualize $\\mathbf{y}$ as an image having the same size as $\\mathbf{x}_t$. This is useful when $\\mathbf{y}$ does not have the same size, e.g. for super-resolution...)\n",
        "2. Test it with the inpainting example below.\n",
        "3. Define the operator to solve a x4 super-resolution problem and test it on some portrait image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaQqH-WdR9Cr"
      },
      "outputs": [],
      "source": [
        "h = 256\n",
        "w = 256\n",
        "hcrop, wcrop = h//2, w//2\n",
        "corner_top, corner_left = h//4, int(0.45*w)\n",
        "mask = torch.ones(ddpm.imgshape, device=device)\n",
        "mask[:,:,corner_top:corner_top+hcrop,corner_left:corner_left+wcrop] = 0\n",
        "\n",
        "def linear_operator(x):\n",
        "  x = x*mask\n",
        "  return(x)\n",
        "\n",
        "idx = 12\n",
        "x_true_pil = Image.open('ffhq256-1k-validation/'+str(idx).zfill(5)+'.png')\n",
        "x_true = pilimg_to_tensor(x_true_pil)\n",
        "print(x_true.device)\n",
        "print(\"original image\", str(idx).zfill(5)+'.png')\n",
        "display_as_pilimg(x_true)\n",
        "\n",
        "sigma_noise = 2*10/255\n",
        "\n",
        "y = linear_operator(x_true.clone()) + sigma_noise * mask * torch.randn_like(x_true)\n",
        "print(\"noisy measurement\")\n",
        "display_as_pilimg(y);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCzfALMZSPgA"
      },
      "outputs": [],
      "source": [
        "ddpm.posterior_sampling(linear_operator, y, x_true=x_true, show_steps=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 4: ODE sampler: From DDPM to backward SDE to probability flow ODE"
      ],
      "metadata": {
        "id": "tYHG6kYSEk7P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This exercise has been elaborated with the help of [Emile Pierret](https://www.idpoisson.fr/pierret) and is inspired by:\n",
        "* *Score-Based Generative Modeling through Stochastic Differential Equations*,\n",
        "Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon, Ben Poole, ICLR 2021 https://arxiv.org/abs/2011.13456\n",
        "\n",
        "As recalled in Exercise 2, the DDPM transition probability is given by\n",
        "$$ p_\\theta(\\bx_{t-1}|\\bx_{t}) = \\mathcal{N}(\\mu_\\theta(\\bx_{t}, t), \\beta_t I_d) $$\n",
        "where\n",
        "$$\n",
        "\\mu_\\theta(\\bx_t, t) = \\frac{1}{\\sqrt{\\alpha_t}} \\left(\\bx_t - \\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}_t}}\\mathbf{\\varepsilon}_\\theta(\\bx_t,t) \\right).\n",
        "$$\n",
        "This results in the sampling scheme:\n",
        "$$\n",
        "\\bx_{t-1}\n",
        "= \\frac{1}{\\sqrt{\\alpha_t}} \\left(\\bx_t - \\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}_t}}\\mathbf{\\varepsilon}_\\theta(\\bx_t,t) \\right) + \\sqrt{\\beta_t} \\bz_t,\\quad \\bz_t\\sim \\mathcal{N}(0, I_d).\n",
        "$$\n",
        "Now, by Tweedie formula we know that the score function is linked to the noise $\\varepsilon$:\n",
        "$$\n",
        "\\mathbb{E}\\left[ \\varepsilon|\\bx_t\\right] = - \\sqrt{1-\\bar{\\alpha}_t} \\nabla_{\\bx_t} \\log p_{t}(\\bx_t).\n",
        "$$\n",
        "Hence we can defined the learnt score function as:\n",
        "$$\n",
        "s_\\theta(\\bx_t,t) = - \\frac{1}{\\sqrt{1-\\bar{\\alpha}_t}}\\mathbf{\\varepsilon}_\\theta(\\bx_t,t).\n",
        "$$\n",
        "The DDPM with the learnt score function is thus:\n",
        "$$\n",
        "\\bx_{t-1}\n",
        "= \\frac{1}{\\sqrt{\\alpha_t}} \\left(\\bx_t + \\beta_t s_\\theta(\\bx_t,t)\\right) + \\sqrt{\\beta_t} \\bz_t,\\quad \\bz_t\\sim \\mathcal{N}(0, I_d).\n",
        "$$\n",
        "Now since $\\alpha_t = 1 -\\beta_t$ with $\\beta_t$ small by comparison of the time step $\\Delta t=1$, we can approximate\n",
        "$$\n",
        "\\frac{1}{\\sqrt{\\alpha_t}}\n",
        "= \\frac{1}{\\sqrt{1 - \\beta_t}}\n",
        "\\approx 1 + \\frac{1}{2} \\beta_t.\n",
        "$$\n",
        "This gives the approximate sampling scheme:\n",
        "$$\n",
        "\\bx_{t-1}\n",
        "= \\bx_t + \\frac{1}{2} \\beta_t x_t + \\beta_t s_\\theta(\\bx_t,t) + \\sqrt{\\beta_t} \\bz_t,\\quad \\bz_t\\sim \\mathcal{N}(0, I_d).\n",
        "$$\n",
        "This is an Euler-Maruyama scheme with step $\\Delta t=1$ for the diffusion SDE:\n",
        "$$\n",
        "d\\bx_t = \\frac{1}{2} \\beta_t x_t dt + \\beta_t \\nabla_\\bx\\log  p_t(\\bx_t)dt + \\sqrt{\\beta_t} d \\bw_t\n",
        "$$\n",
        "with the learnt score function $s_\\theta$.\n",
        "The corresponding probability flow ODE is:\n",
        "$$\n",
        "d\\bx_t = \\frac{1}{2} \\beta_t x_t dt + \\frac{1}{2}  \\beta_t \\nabla_\\bx\\log  p_t(\\bx_t) dt.\n",
        "$$\n",
        "**Questions:**\n",
        "\n",
        "1. Add a method ```ode_euler_sampling``` to the DDPM class with prototype <br/>\n",
        "`ode_euler_sampling(self, nb_times_integration=1000, noise_seed = None, show_steps=True)` <br/>\n",
        "that samples the above probability flow ODE with ```nb_times_integration```steps (supposed to be a divisor of $T=1000$) and accepts a seed to draw the initial Gaussian noise at $T=1000$.  <br/>\n",
        "Test the function with various seed.\n",
        "2. Test the ```ode_euler_sampling``` function with the same seed with the various number of steps 20, 50, 100 and 200, 1000. Comment the results.\n",
        "3. Define a function ```ode_euler_samples_interpolation``` to the DDPM class with prototype <br/>\n",
        "`ode_euler_samples_interpolation(self, nb_times_integration=100, noise_seed0 = None, noise_seed1 = None, n_interm = 7)` <br/>\n",
        "that performs samples interpolation by linearly interpolating the initial noises:\n",
        "$$\n",
        "\\bx_T^\\gamma =  (1-\\gamma) \\bx_T^0 + \\gamma \\bx_T^1.\n",
        "$$\n",
        "Are the interpolation results satisfying ?\n",
        "4. Propose and test a better solution for sample interpolation.\n"
      ],
      "metadata": {
        "id": "NGyl03TUEpDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 4.1)\n",
        "ddpm.ode_euler_sampling(nb_times_integration=1000,\n",
        "                        noise_seed = 20250225,\n",
        "                        show_steps=True);"
      ],
      "metadata": {
        "id": "ri-CH6IrEn7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "BldMVnXBE8uj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}