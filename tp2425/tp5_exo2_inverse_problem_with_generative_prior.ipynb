{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MachaBar/PROJET-LU2IN013/blob/main/tp2425/tp5_exo2_inverse_problem_with_generative_prior.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-UDPsOWavHD"
      },
      "source": [
        "# Exercise 2: Generative prior for imaging inverse problems\n",
        "\n",
        "<br/><br/>\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/generativemodelingmva/generativemodelingmva.github.io/blob/main/tp2425/tp5_exo2_inverse_problem_with_generative_prior.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "<br/><br/>\n",
        "\n",
        "**Authors:**\n",
        "\n",
        "Bruno Galerne: https://www.idpoisson.fr/galerne/\n",
        "\n",
        "Arthur Leclaire: https://perso.telecom-paristech.fr/aleclaire/\n",
        "\n",
        "<br/><br/>\n",
        "You should complete the code regions marked withÂ `### ... ###`\n",
        "\n",
        "\n",
        "<br/><br/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30aVL7sPoj_3"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')\n",
        "\n",
        "# # default directory:\n",
        "# %cd /content/drive/MyDrive/Colab\\ Notebooks\n",
        "# # we advise to create a specific directory on your Google drive:\n",
        "# %cd /content/drive/MyDrive/genmod2425"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJ2qQFGZa2Xz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torch.autograd as autograd\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "def stretch(x):\n",
        "# stretch values such that [min. max]->[0,1]\n",
        "    m = torch.min(x)\n",
        "    M = torch.max(x)\n",
        "    if M>m:\n",
        "        return((x-m)/(M-m))\n",
        "    else:\n",
        "        return(torch.zeros(x.shape))\n",
        "\n",
        "def imshow(img, unnormalize=False, zoom_factor=3, stretch_opt=False):\n",
        "    img = img.clone().detach().to('cpu')\n",
        "    if unnormalize:\n",
        "        img = img*0.5 + 0.5     # unnormalize\n",
        "    if stretch_opt:\n",
        "        img = stretch(img)\n",
        "    if zoom_factor!=1:\n",
        "        img = torch.kron(img, torch.ones(1,zoom_factor,zoom_factor))\n",
        "    pil_img = torchvision.transforms.functional.to_pil_image(1-img)\n",
        "    display(pil_img)\n",
        "    return(pil_img)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7f0k9-xa24G"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this notebook we will use a generative model as an image prior to solve an imaging inverse problem.\n",
        "This amounts to limit the space of images to the subset\n",
        "$$\n",
        "\\{x = G(z),~z\\in\\mathbb{R}^k\\} \\subset \\mathbb{R}^d\n",
        "$$\n",
        "to solve a least squares inverse problem\n",
        "$$\n",
        "\\min_{x} \\|Ax - y \\|^2.\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YA9XsNIIdZR6"
      },
      "source": [
        "## Load pretrained generative network:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6poLRKJeYoW",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# load a pre-trained generative network\n",
        "!wget -c 'https://www.idpoisson.fr/galerne/mva/GAN_G_net_ep100.pth'\n",
        "\n",
        "# Generator network:\n",
        "class G_Net(nn.Module):\n",
        "  def __init__(self, k):\n",
        "    super(G_Net, self).__init__()\n",
        "    self.fc1 = nn.Linear(k, 256)\n",
        "    self.fc2 = nn.Linear(256, 512)\n",
        "    self.fc3 = nn.Linear(512, 784)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.fc1(x)\n",
        "    x = F.leaky_relu(x, negative_slope=0.2)\n",
        "    x = self.fc2(x)\n",
        "    x = F.leaky_relu(x, negative_slope=0.2)\n",
        "    x = self.fc3(x)\n",
        "    x = torch.tanh(x)\n",
        "    x = x.view(-1,1,28,28) # batch_size x channels x H x W\n",
        "    return(x)\n",
        "\n",
        "def show(G,z=None):\n",
        "  # provide random latent code as option to see evolution\n",
        "  with torch.no_grad():\n",
        "    if z==None:\n",
        "      z = torch.randn(100,k).to(device)\n",
        "    genimages = G(z)\n",
        "    pil_img = imshow(torchvision.utils.make_grid(genimages.to('cpu'),nrow=10))\n",
        "    return(pil_img)\n",
        "    #print(disnet(genimages))\n",
        "\n",
        "# initialize generator (with random weights)\n",
        "k = 32\n",
        "G_net = G_Net(k).to(device)\n",
        "z = torch.randn(100,k).to(device)\n",
        "\n",
        "print(\"Generator with random init:\")\n",
        "show(G_net);\n",
        "G_net.load_state_dict(torch.load('GAN_G_net_ep100.pth', map_location=device))\n",
        "G_net.eval()\n",
        "G_net.requires_grad_(False)\n",
        "print(\"Pretrained generator:\")\n",
        "show(G_net,z=z);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A23ZzXYBi3Z0"
      },
      "source": [
        "## Operator of inverse problem\n",
        "\n",
        "Implement an operator $A$ that does crude subsampling with stride s.\n",
        "Implement also a version of $A$ that applies on a batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNwZTqkpi7za"
      },
      "outputs": [],
      "source": [
        "# the input x is a gray-level image of shape 1xMxN\n",
        "def A(x,s=2):\n",
        "    return ### ... ###\n",
        "\n",
        "# the input x is a batch of gray-level images of shape bx1xMxN\n",
        "def batchA(x,s=2):\n",
        "    return ### ... ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS5NDkmsiUhp"
      },
      "source": [
        "## Input data\n",
        "\n",
        "We will consider images from the **MNIST test set** and a generative model trained as a GAN using a the disjoint **MNIST training set**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtUv9r9Zeny3"
      },
      "outputs": [],
      "source": [
        "# input\n",
        "# transformtest = transforms.ToTensor()\n",
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])\n",
        "datatest = datasets.MNIST('.', train=False, download=True, transform=transform)\n",
        "input_idx = 0 # a seven\n",
        "#input_idx = 99 # a nine\n",
        "#input_idx = 3 # a zero\n",
        "#input_idx = 5 # a one\n",
        "#input_idx = 21 # a six\n",
        "#input_idx = 1 # a two\n",
        "#input_idx = 4 # a four\n",
        "#input_idx = 1984 # an unusual 2, hard\n",
        "\n",
        "\n",
        "x0=  datatest[input_idx][0].to(device)\n",
        "_, M, N = x0.shape\n",
        "d = M*N\n",
        "imshow(x0);\n",
        "\n",
        "# compute a sample of the direct model y = Ax0 + w\n",
        "y = ### ... ###\n",
        "\n",
        "imshow(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Em6PzSBL9tl"
      },
      "source": [
        "## Pseudo-inverse of operator\n",
        "\n",
        "Compute the $A^+ y$ by applying gradient descent to the convex function\n",
        "$$\n",
        "f(x) = \\|Ax - y \\|^2\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EkMH-U8ij4g"
      },
      "outputs": [],
      "source": [
        "x = torch.zeros(x0.shape).to(device)\n",
        "x.requires_grad = True\n",
        "\n",
        "# compute pseudo-inverse of y\n",
        "optimizer = optim.SGD([x], lr = 0.01, momentum = 0.9)\n",
        "niter = 1000\n",
        "for it in range(niter):\n",
        "    optimizer.zero_grad()\n",
        "    fx = ### ... ###\n",
        "    fx.backward()\n",
        "    optimizer.step()\n",
        "    if fx.item()<1e-10:\n",
        "        print(\"Convergence reached:\")\n",
        "        print(\"iteration \", it, \"fx = \", fx.item())\n",
        "        imshow(x);\n",
        "        break\n",
        "    if it%(niter//10) == niter//10-1:\n",
        "        print(\"iteration \", it, \"fx = \", fx.item())\n",
        "        imshow(x);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmbLYpbBY7an"
      },
      "source": [
        "## GAN prior for solving the inverse problem\n",
        "We solve for\n",
        "$$\n",
        "\\hat x = G(\\hat z)\n",
        "\\quad \\text{with $\\hat z$ solution of}\\quad\n",
        "\\min_{z\\in\\mathbb{R}^{k}} \\|A(G(z)) - y \\|^2.\n",
        "$$\n",
        "Since the result highly depends on the initialization, we will optimize for a batch of $b=10$ $z$ values.\n",
        "\n",
        "**Exercise:**\n",
        "Implement a script that:\n",
        "1. Initialize an array $z = (z^0, \\dots, z^{b-1})$ of $b$ random latent code.\n",
        "2. Optimize $z$ to minimize the sum\n",
        "$$\n",
        "\\sum_{j=0}^{b-1} \\|A(G(z^j)) - y \\|^2\n",
        "$$\n",
        "using ```optim.Adam([z], lr = 0.01)``` as optimizer for ```niter = 10**4```.\n",
        "3. Display the $b=10$ corresponding images $G(z^j)$ at initialization and at 10 intermediary steps as well as the iteration number and the value of the function to optimize."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBpesFygYV2C",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "\n",
        "# initialize z\n",
        "### ... ###\n",
        "\n",
        "optimizer = optim.Adam([z], lr = .01)\n",
        "\n",
        "print('Solution:')\n",
        "imshow(x0, False);\n",
        "niter = 10**4\n",
        "losslist = []\n",
        "\n",
        "for it in range(niter):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    fx = ### ... ###\n",
        "    fx.backward()\n",
        "    optimizer.step()\n",
        "    losslist.append(fx.item())\n",
        "\n",
        "    if it==0 or it%(niter//10) == niter//10-1:\n",
        "        print(\"iteration \", it, \"fx = \", fx.item())\n",
        "        show(G_net,z=z)\n",
        "\n",
        "plt.plot(losslist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbOuZtxbybKj"
      },
      "source": [
        "#Â Repeat the experiment with a DCGAN pre-learned with WGAN-GP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWjZKoa2oj_7"
      },
      "outputs": [],
      "source": [
        "nz = 100\n",
        "ngf = 64\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels = nz, out_channels = ngf * 8, kernel_size = 4, stride = 1, padding = 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(in_channels = ngf * 8, out_channels = ngf * 4, kernel_size = 4, stride = 2, padding = 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d(in_channels = ngf * 4, out_channels = ngf * 2, kernel_size = 4, stride = 2, padding = 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d(in_channels = ngf * 2, out_channels = ngf, kernel_size = 4, stride = 2, padding = 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d(in_channels = ngf, out_channels = 1, kernel_size=1, stride=1, padding=2, bias=False),\n",
        "            nn.Tanh()\n",
        "            # output size. 1 x 28 x 28\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "# download a prelearned DCGAN (see Practical Session 3)\n",
        "G = Generator().to(device)\n",
        "G.load_state_dict(torch.hub.load_state_dict_from_url('https://perso.telecom-paristech.fr/aleclaire/mva/tp/wgan_epoch100.pt', progress=False))\n",
        "G.eval();  # Turn generator in evaluation mode to fix BatchNorm layers\n",
        "\n",
        "G_net.eval()\n",
        "G.requires_grad_(False)\n",
        "zt = torch.randn(b,nz,1,1).to(device)\n",
        "show(G,zt);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "pptfpnEnoj_7"
      },
      "outputs": [],
      "source": [
        "### ... ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ix52JtIHoj_7"
      },
      "source": [
        "## Adjust the exercise for simple denoising ($A= \\mathsf{Id}$)\n",
        "\n",
        "Remark that it is equivalent to a simple GAN inversion.\n",
        "\n",
        "On a batch of sampled images $x$, compute the average value of $\\|G(z_*) - x\\|$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pByOE5r1oj_7"
      },
      "outputs": [],
      "source": [
        "### ... ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5maEkhGCoj_7"
      },
      "source": [
        "## Repeat the exercise with the operator A defined in the next cell\n",
        "\n",
        "We will now define a new operator $A$ that sums the values of the gray-level image along each vertical, horizontal and diagonal directions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TH3p5m6foj_7"
      },
      "outputs": [],
      "source": [
        "# We suppose that:\n",
        "#  - the input x is a square gray-level image of size 1xMxN with M=N\n",
        "#  - the output y is 1D tensor of size number of measurements m\n",
        "\n",
        "def sum_all_diagonal_matrix(mat: torch.tensor):\n",
        "    # from: https://stackoverflow.com/questions/57347896/sum-all-diagonals-in-feature-maps-in-parallel-in-pytorch\n",
        "    n,_ = mat.shape\n",
        "    zero_mat = torch.zeros((n, n),device=mat.device) # Zero matrix used for padding\n",
        "    mat_padded =  torch.cat((zero_mat, mat, zero_mat), 1) # pads the matrix on left and right\n",
        "    mat_strided = mat_padded.as_strided((n, 2*n), (3*n + 1, 1)) # Change the strides\n",
        "    sum_diags = torch.sum(mat_strided, 0) # Sums the resulting matrix's columns\n",
        "    return(sum_diags[1:])\n",
        "\n",
        "def axial_and_diagonal_sum(x):\n",
        "    # sum over diagoanal:\n",
        "    _,M,N = x.shape\n",
        "    xmat = x.reshape(M,N)\n",
        "    yhori = torch.sum(x, axis=2).flatten()\n",
        "    yvert = torch.sum(x, axis=1).flatten()\n",
        "    ydiag = sum_all_diagonal_matrix(xmat).flatten()\n",
        "    y_anti_diag = sum_all_diagonal_matrix(xmat.flip(1)).flatten()\n",
        "    y = torch.cat((yhori, yvert, ydiag, y_anti_diag.flip(0)))\n",
        "    return(y)\n",
        "\n",
        "# test of axial_and_diagonal_sum(x)\n",
        "t = torch.diag(1+torch.arange(4)).unsqueeze(0)\n",
        "print(\"Test of axial_and_diagonal_sum(x):\")\n",
        "print(\"Input:\", t)\n",
        "print(\"Output:\", axial_and_diagonal_sum(t))\n",
        "\n",
        "opA = axial_and_diagonal_sum\n",
        "\n",
        "    def batchopA(x):\n",
        "    # apply opA to each image of a batch and return a tensor:\n",
        "    listAx = []\n",
        "    for bidx in range(x.shape[0]):\n",
        "        listAx.append(opA(x[bidx,:,:]))\n",
        "    Ax = torch.stack(listAx)\n",
        "    return(Ax)\n",
        "\n",
        "\n",
        "### ... Try y = Ax ... ##\n",
        "\n",
        "# print('Plot of y: (yhori, yvert, ydiag, y_anti_diag)')\n",
        "# plt.figure(figsize=(20,4))\n",
        "# plt.bar(range(y.numel()), y.to('cpu').numpy());\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}